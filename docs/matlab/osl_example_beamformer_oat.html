---
layout: matlab_wrapper
title: OAT 3 - Sourcespace Analysis
resource: true
categories: examples
---

<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <title>OAT 3 - Sourcespace Analysis</title><meta name="generator" content="MATLAB 8.4"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2017-04-24"><meta name="DC.source" content="osl_example_beamformer_oat.m"></head><body><div class="content"><h1>OAT 3 - Sourcespace Analysis</h1><!--introduction--><p>This practical will work with a single subject's data from an emotional faces experiment (Elekta Neuromag data).</p><p>Work your way through the script cell by cell using the supplied dataset. As well as following the instructions below, make sure that you read all of the comments and understand each step as you go.</p><p>We will estimate neural activity in the brain's source space using a beamformer algorithm, task dependant differences in this source activity is then quantified using a GLM. This will go through the following steps:</p><div><ol><li>Set-up an OAT Analysis: source_recon and first_level</li><li>Run source space GLM fitting and contrasts</li><li>Check coregistration</li><li>Save and view t-stat volumes</li><li>GLM analysis in an ROI</li><li>Time-frequency analysis in an ROI</li><li>Whole brain time-frequency analysis</li></ol></div><p>This practical requires the first part of the osl_example_coregistration practical to be run first. If you haven't run this before, please do so before starting this session.</p><!--/introduction--><h2>Contents</h2><div><ul><li><a href="#1">INITIALISE GLOBAL SETTINGS FOR THIS ANALYSIS</a></li><li><a href="#2">SET UP THE SUBJECTS FOR THE ANALYSIS</a></li><li><a href="#3">SETUP THE OAT:</a></li><li><a href="#4">SPECIFIY FIRST LEVEL OPTIONS</a></li><li><a href="#5">RUN THE OAT:</a></li><li><a href="#6">VIEW OAT  REPORT</a></li><li><a href="#7">OUTPUT SUBJECT'S NIFTII FILES</a></li><li><a href="#8">OPEN NIFTII RESULTS IN FSLVIEW</a></li><li><a href="#9">VIEW RESULTS IN FLSVIEW</a></li><li><a href="#10">INVESTIGATING LOCATION OF INTEREST USING AN MNI COORDINATE</a></li><li><a href="#11">INVESTIGATING REGIONS OF INTEREST USING AN MNI MASK</a></li><li><a href="#12">TIME-FREQUENCY ANALYSIS ACROSS A SOURCE-SPACE PARCELLATION</a></li><li><a href="#13">VIEW THE RESULTS IN THE OAT REPORT</a></li><li><a href="#14">SOURCE ROI TIME-FREQUENCY PLOT</a></li><li><a href="#15">SOURCE ROI SINGLE-FREQUENCY POWER PLOT</a></li></ul></div><h2 id="1">INITIALISE GLOBAL SETTINGS FOR THIS ANALYSIS</h2><p>This cell sets the directory that OAT will work in. Change the workingdir variable to correspond to the correct directory on your computer before running the cell.</p><pre class="codeinput"><span class="comment">% directory where the data is:</span>
datadir = fullfile(osldir,<span class="string">'example_data'</span>,<span class="string">'faces_singlesubject'</span>,<span class="string">'spm_files'</span>);
structdir =  fullfile(osldir,<span class="string">'example_data'</span>,<span class="string">'faces_singlesubject'</span>,<span class="string">'structurals'</span>);

<span class="comment">% directory to put the analysis in</span>
workingdir = fullfile(osldir,<span class="string">'example_data'</span>,<span class="string">'faces_subject1_data_osl2'</span>);
</pre><h2 id="2">SET UP THE SUBJECTS FOR THE ANALYSIS</h2><p>Specify a list of the fif files, structural files (not applicable for this practical) and SPM files (which will be created). It is important to make sure that the order of these lists is consistent across sessions. Note that here we only have 1 subject, but more generally there would be more than one. For example:</p><p><tt>fif_files{1}=[testdir '/fifs/sub1_face_sss.fif'];</tt></p><p><tt>fif_files{2}=[testdir '/fifs/sub2_face_sss.fif'];</tt></p><p>etc...</p><p><tt>spm_files{1} = [workingdir '/sub1_face_sss.mat'];</tt></p><p><tt>spm_files{2} = [workingdir '/sub2_face_sss.mat'];</tt></p><p>etc...</p><pre class="codeinput"><span class="comment">% clear old spm files</span>
clear <span class="string">spm_files_continuous</span> <span class="string">spm_files_epoched</span>

spm_files_continuous{1}=[datadir <span class="string">'/Aface_meg1.mat'</span>];
spm_files_epoched{1}=[datadir <span class="string">'/eAface_meg1.mat'</span>];
</pre><h2 id="3">SETUP THE OAT:</h2><p>The oat.source_recon options define the parameters for the data filtering, windowing and beamforming. We define the D files, conditions and time-frequency options in the same way as the sensorspace OAT. THe In this section we will do a wholebrain beamformer, followed by a trial-wise GLM that will correspond to a comparison of the ERFs for the different conditions. The source-space projection is defined by a new set of options.</p><p>The critical options are:</p><div><ul><li><tt>method</tt> -   This defines the source reconstruction method to be used. other options include 'beamform_bilateral' and 'mne_datacov'</li><li><tt>normalise_method</tt> - How to normalise the magnetometers and gradiometers</li><li><tt>gridstep</tt> - This is the distance (in mm) between points to be reconstructed, the spatial resolution of the analysis. We are using 8mm which is lower than usual but faster to compute.</li><li><tt>forward_meg</tt> - This specifies the forward model used.</li><li><tt>modalities</tt> - Defines which types of sensor to use.</li><li><tt>do_source_variance_maps</tt> - If set to 1, this outputs an optional sanity check</li></ul></div><pre class="codeinput"><span class="comment">% These options are the same as the sensorspace OAT and define input-data,</span>
<span class="comment">% conditions, filtering and windowing.</span>
oat=[];
oat.source_recon.D_continuous=spm_files_continuous;
oat.source_recon.D_epoched=spm_files_epoched;

oat.source_recon.conditions={<span class="string">'Motorbike'</span>,<span class="string">'Neutral face'</span>,<span class="string">'Happy face'</span>,<span class="string">'Fearful face'</span>};
oat.source_recon.freq_range=[3 40]; <span class="comment">% frequency range in Hz</span>
oat.source_recon.time_range=[-0.2 0.4]; <span class="comment">% time range in secs</span>

<span class="comment">% These options specify the source reconstruction that will take place.</span>
oat.source_recon.method=<span class="string">'beamform'</span>;
oat.source_recon.normalise_method=<span class="string">'mean_eig'</span>;
oat.source_recon.gridstep=8; <span class="comment">% in mm</span>
oat.source_recon.forward_meg=<span class="string">'Single Shell'</span>;
oat.source_recon.modalities{1}={<span class="string">'MEGPLANAR'</span>, <span class="string">'MEGMAG'</span>};
oat.source_recon.report.do_source_variance_maps=1;

oat.source_recon.dirname=[workingdir <span class="string">'/beamformer_erf'</span>]; <span class="comment">% directory the oat and results will be stored in</span>
</pre><h2 id="4">SPECIFIY FIRST LEVEL OPTIONS</h2><p>These options are the same as the sensorspace ERF tutorial.</p><p>design_matrix_summary is a parsimonious description of the design matrix. It contains values <tt>design_matrix_summary{reg,cond}</tt>, where reg is a regressor no. and cond is a condition no. This will be used (by expanding the conditions over trials) to create the (num_regressors x num_trials) design matrix:</p><pre class="codeinput">design_matrix_summary={};
design_matrix_summary{1}=[1 0 0 0];design_matrix_summary{2}=[0 1 0 0];design_matrix_summary{3}=[0 0 1 0];design_matrix_summary{4}=[0 0 0 1];
oat.first_level.design_matrix_summary=design_matrix_summary;

<span class="comment">% contrasts to be calculated:</span>
oat.first_level.contrast={};
oat.first_level.contrast{1}=[3 0 0 0]'; <span class="comment">% motorbikes</span>
oat.first_level.contrast{2}=[0 1 1 1]'; <span class="comment">% faces</span>
oat.first_level.contrast{3}=[-3 1 1 1]'; <span class="comment">% faces-motorbikes</span>
oat.first_level.contrast_name={};
oat.first_level.contrast_name{1}=<span class="string">'motorbikes'</span>;
oat.first_level.contrast_name{2}=<span class="string">'faces'</span>;
oat.first_level.contrast_name{3}=<span class="string">'faces-motorbikes'</span>;
oat.first_level.report.first_level_cons_to_do=[2 1 3];

oat.first_level.time_range=[-0.1 0.3];
oat.first_level.post_tf_downsample_factor=1;
oat.first_level.name=[<span class="string">'wholebrain_first_level'</span>];

oat = osl_check_oat(oat);
</pre><h2 id="5">RUN THE OAT:</h2><p>We only need to run the source_recon and first_level stages in this tutorial, the subject_level and group_level options can be set to 0.</p><p>The OAT will produce and close a number of figures as it processes, we will discuss what they mean once it has finished (this takes a couple of minutes)</p><pre class="codeinput">oat.to_do=[1 1 0 0];
oat = osl_run_oat(oat);
</pre><h2 id="6">VIEW OAT  REPORT</h2><p>Once finished, the OAT will print a link to a html report. Click to open it in the matlab html browser.</p><p><b>Source Recon</b></p><p>Firstly, click to open the "Session_1_report". This contains the plots relevent to the source_recon. In our case this is the sensor normalisation. Note that the eigenspectrum of the sensordata ('Pre-normalised log eigenspectrum') drops off sharply at around 64, this indicates the rank of the sensor data which i limited by maxfilter de-noising.</p><p>The Pre-normalised variances shows the sensor-by-sensor variance across time. Channels 205-306 are the Magnetometers and have much higher variance than the Gradiometers. We need to normalise the data to remove this disparity or the information in the Magnetometers will dominate the reconstruction.</p><p>In the normalised_eigs plot below, we can see that the 'mean_eig' sensor normalisation has both removed the shelf in the eigenspectrum and brought the sensor variances in line with each other.</p><p><b>First Level</b></p><p>Click back to the first page and on to the 'First level (epoched) report' and then the 'session1 report'. This contains a results summary from the voxel-wise GLM</p><p>Design matrix plot. At the top is the design matrix used for each subject. Red values indicate a value of 1, blue indicates a value of zero. It is worth noting if every regressor (in this case corresponding to the four different conditions) is well represented. For example, if aggressive amounts of outlier rejection has been applied then it is possible to end up with very few trials in a regressor.</p><p><b>Stats plots</b> These show the time courses of the COPEs and t-stats for the different contrasts listed in <tt>oat.first_level.report.first_level_cons_to_do</tt>, at the MNI coordinated indicated in the title of the plots. This MNI coordinate is chosen by finding the voxel with the maximum t-stat for the first contrast listed in <tt>oat.first_level.report.first_level_cons_to_do</tt>.</p><p>The COPE is on the left and the t-stat on the right. Note the large peak around 96ms after stimulus onset.</p><p><b>COPE and t-stat orthoview plots</b> These show orthoviews of the COPEs and t-stats for the different contrasts listed in <tt>oat.first_level.report.first_level_cons_to_do</tt>, at the time point indicated in the title of the plots. This time point is chosen by finding the time point with the maximum t-stat for the first contrast listed in <tt>oat.first_level.report.first_level_cons_to_do</tt>.</p><p>This time-point is around 136ms and shows peaks in lateral and medial occipital cortex. These are right hemisphere lateralised for the Faces and Faces-Motorbikes condition.</p><p><img vspace="5" hspace="5" src="osl_example_beamformer_oat_cope_at_maxt_smap_c2.png" alt=""> </p><h2 id="7">OUTPUT SUBJECT'S NIFTII FILES</h2><p>The html report gives a brief summary of the results but we would like to go into more detail.</p><p>We can do this by saving the contrast of parameter estimates (COPEs) and t-statistics for each of our contrasts to NIFTI images.</p><pre class="codeinput">S2=[];
S2.oat=oat;
S2.stats_fname=oat.first_level.results_fnames{1};
S2.first_level_contrasts=[3,1,2];
S2.resamp_gridstep=oat.source_recon.gridstep;
[statsdir,times,count]=oat_save_nii_stats(S2);
</pre><h2 id="8">OPEN NIFTII RESULTS IN FSLVIEW</h2><p>We can now view the nifti images containing our GLM results in FSL, here we are running fslview from the matlab command line, but you do not need to - you can run it from the UNIX command line instead.</p><pre class="codeinput">mni_brain=[osldir <span class="string">'/std_masks/MNI152_T1_'</span> num2str(S2.resamp_gridstep) <span class="string">'mm_brain.nii.gz'</span>];

<span class="comment">% Inspect the results of an OAT contrast in FSLVIEW</span>
contrast=2;
runcmd([<span class="string">'fslview '</span> mni_brain <span class="string">' '</span> [statsdir <span class="string">'/tstat'</span> num2str(contrast) <span class="string">'_'</span> num2str(S2.resamp_gridstep) <span class="string">'mm'</span>] <span class="string">' &amp;'</span>]);
</pre><h2 id="9">VIEW RESULTS IN FLSVIEW</h2><p>The previous command should have opened FSLVIEW with the t-stats for the faces contrast. We need to tweat the viewing settings to see the results well.</p><p>Firstly, make sure the 'tstat2_8mm' image in selected by clicking on it once in the bottom window. Next set the 'Min' and 'Max' to 15 and 25 respectively in the two boxes in the middel at the top of the screen.</p><p>We are currently looking at the first time-point in the source_recon window which corresponds to -100ms, in which not much is happening.</p><p>Change the 'Volume' in the bottom left to 49, this corresponds to around 100ms after stimulus onset. You should see a response in early visual cortex at the back of the brain. You can cross-check the times referred to in the Volumes with the 'times' variable returned by 'oat_save_nii_stats' above (Note that FSLVIEW indexes Volumes from 0 and Matlab indexes times from 1)</p><p>Now change the 'Volume' to 59, corresponding to around 140ms after stimulus onset. The peak of activation jumps to the right hemiphere visual cortex.</p><p>You can futher investigate the results by clicking on the 'Tools-&gt;Timeseries' option in the top menu. This will bring up and new window showing the t-value across time for the voxel under the green curser. You can navigate across space by clicking on a part of the brain and time by clicking at a time-point on the timeseries.</p><p>Try changing to code in the previous cell to bring up the tstats for contrast 3 'Face-Motorbikes'. Following the same visualisation instructions you should be able to see that the early time-window (Volume 49) does not contain any large responses whereas the later response (Volume 59) still occurs. This indicates that there are no large differences between Faces and Motorbikes in the the early response, whereas the later response does differ.</p><pre class="codeinput"><span class="comment">% Display the vector of times associated with Volumes in the Nifti output.</span>
disp(times)
</pre><h2 id="10">INVESTIGATING LOCATION OF INTEREST USING AN MNI COORDINATE</h2><p>We may want to see the results across all contrasts for a single ROI to gain another perspective on our results.</p><p>Here we will interrogate the wholebrain OAT (run above) using a specified MNI coordinate.</p><p>Run the code below now. This will bring up a the COPE and tstat estimates across time for a voxel in visual cortex. Note the prominant response around 100ms</p><p>Try changing the code to run at 32,-64,-18</p><p>This corresponds to a point in Right Hemisphere Fusiform Cortex. Note that the 100ms response does not appear here, rather the later Face specific response is more dominant.</p><pre class="codeinput">mni_coord=[4,-82,-8]; <span class="comment">% Visual Cortex Voxel</span>

S2=[];
S2.vox_coord=mni_coord;
S2.stats=oat.first_level.results_fnames{1};
S2.oat=oat;
S2.first_level_cons_to_do=oat.first_level.report.first_level_cons_to_do; <span class="comment">% plots all of these contrasts</span>

[vox_ind_used] = oat_plot_vox_stats(S2);
</pre><img vspace="5" hspace="5" src="osl_example_beamformer_oat_01.png" alt=""> <h2 id="11">INVESTIGATING REGIONS OF INTEREST USING AN MNI MASK</h2><p>In this section we will interrogate the wholebrain OAT (run above) using an ROI mask. Here we will use an MNI mask of the right temporal occipital fusiform cortex, to perform first level statistics restricted to the mask. The final result will correspond to a spatial average over the mask.</p><p>Unlike the virtual electrode, the results from many voxels (all defined in the binary mask in <tt>S2.mask_fname</tt>) are extracted and the average results across these points presented.</p><pre class="codeinput"><span class="comment">% Apply a mask and spatially average the results over an ROI</span>
S2=[];
S2.oat=oat;
S2.stats_fname=oat.first_level.results_fnames{1};
S2.mask_fname=fullfile(osldir,<span class="string">'example_data'</span>,<span class="string">'faces_singlesubject'</span>,<span class="string">'structurals'</span>,<span class="string">'Right_Temporal_Occipital_Fusiform_Cortex_8mm.nii.gz'</span>);
[stats,times,mni_coords_used]=oat_output_roi_stats(S2);

<span class="comment">% Plot the COPEs and t-stats within the ROI</span>
S2=[];
S2.stats=stats;
S2.oat=oat;
S2.first_level_cons_to_do=oat.first_level.report.first_level_cons_to_do; <span class="comment">% plots all of these contrasts</span>
[vox_ind_used] = oat_plot_vox_stats(S2);
</pre><img vspace="5" hspace="5" src="osl_example_beamformer_oat_02.png" alt=""> <h2 id="12">TIME-FREQUENCY ANALYSIS ACROSS A SOURCE-SPACE PARCELLATION</h2><p>Often we want to interrogate neuronal responses in the frequency domain rather than the time-domain ERF. As we saw in the sensor-space practical we can extend the OAT to compute the GLM across a time-frequency decomposition of the data. Here we will extend the analysis to compute the first level GLM across a detailed time-frequency decomposition.</p><p>The GLM across the full time-frequency decomposition takes much longer to compute than the ERF or power within a single frequency band. As such we will run a time-frequency OAT across a 39 node source-space parcellation.</p><p>This has several benefits. Firstly, we can reduce noise by pooling across many voxels within a source parcel and secondly it is much faster to compute time-frequency transforms for 39 parcels than 306 Sensors or ~3500 Voxels. The details of source parcellations are covered in the ROInets practical sessions - for the moment we can consider the parcellation to be simple way to compute the OAT across many Regions of Interest at the same time.</p><p>Most of the OAT settings do not need to be changed for this analysis. We just need to define which parcellation should be applied and add the time-frequency decomposition parameters in the first level.</p><p>We are going to use the wholebrain OAT (which was run above), to make use of the settings and source_recon results already in there. The new time-frequency parameters are:</p><div><ul><li><tt>tf_freq_range</tt> - The lower and upper bounds on the frequency range of interest</li><li><tt>tf_num_freqs</tt> - The number of frequency bands to estimate within the bounds in <tt>tf_freq_range</tt></li><li><tt>tf_method</tt>-  The spectral power estimation method</li><li><tt>tf_hilbert_freq_res</tt> - The resolution to use in the hilbert spectral estimation</li><li><tt>post_tf_downsample_factor</tt>- How much to downsample the tf results</li></ul></div><p>The new parcellation parameters are defined within a <tt>oat.first_level.parcellation</tt> struct. the critical parameters are:</p><div><ul><li><tt>parcellation</tt> - The full path to a nifti file defining the parcellation</li><li><tt>orthogonalisation</tt> - Option to reduce source leakage, in this case we will not apply correction</li><li><tt>method</tt> - method for reconstructing parcel time-course. Options are <tt>PCA</tt>, <tt>mean</tt>, <tt>peakVoxel</tt> and <tt>spatialBasis</tt>.</li></ul></div><pre class="codeinput"><span class="comment">% LOAD PREVIOUSLY RUN OAT</span>
<span class="comment">% We are going to use the wholebrain OAT (which was run above for the ERF</span>
<span class="comment">% analysis), to make use of the settings already in there</span>
oat.source_recon.dirname=[workingdir <span class="string">'/beamformer_erf'</span>]; <span class="comment">% Make sure this matches the dirname used above</span>
oat.first_level.name=[<span class="string">'wholebrain_first_level'</span>];
oat=osl_load_oat(oat);

<span class="comment">% Give the first level analysis a new name to avoid copying over previous</span>
<span class="comment">% first-level analyses:</span>
oat.first_level.name=[oat.first_level.name <span class="string">'_parc'</span> num2str(oat.first_level.parcellation.do)];

oat.source_recon.report.do_source_variance_maps=0;

<span class="comment">% Add first level source recon options</span>
oat.first_level.tf_freq_range=[4 30]; <span class="comment">% frequency range in Hz</span>
oat.first_level.time_range=[-0.1 0.3];
oat.first_level.tf_num_freqs=13;
oat.first_level.tf_method=<span class="string">'morlet'</span>;
oat.first_level.post_tf_downsample_factor=1;

oat.first_level.report.time_range = [.08 .22];
oat.first_level.report.first_level_cons_to_do = [2,1,3];
oat.first_level.bc=[1 1 0]; <span class="comment">% specifies whether or not baseline correction is done for the different contrasts</span>

<span class="comment">% Define the parameters for the parcellation</span>
oat.first_level.parcellation.do=1;

<span class="comment">% Path to the nifti defining the parcellation</span>
parcellationfile=fullfile(osldir,<span class="string">'example_data'</span>,<span class="string">'faces_singlesubject'</span>,<span class="string">'structurals'</span>,<span class="string">'fmri_d100_parcellation_with_PCC_reduced_2mm_ds8mm.nii.gz'</span>);

<span class="comment">% Define the parcellation options.</span>
oat.first_level.parcellation.parcellation=parcellationfile;
oat.first_level.parcellation.orthogonalisation = <span class="string">'none'</span>;
oat.first_level.parcellation.method            = <span class="string">'spatialBasis'</span>;

<span class="comment">% Check and run the source_recon and first_level OAT stges</span>
oat = osl_check_oat(oat);

<span class="comment">% Rerun the first level OAT.</span>
oat.to_do=[1 1 0 0];
oat = osl_run_oat(oat);
</pre><h2 id="13">VIEW THE RESULTS IN THE OAT REPORT</h2><p>As with the other analyses, take a look at the first level summary report. Alongside the first level design matrix, this contains the COPE and t-stat estimates across the whole time-frequency decomposition from the peak ROI. The results are uniform within each parcel in the whole brain orthoplots and indicate the largest responses around 116ms after stimulus onset are in visual cortex for all three contrasts.</p><pre class="codeinput">disp(oat.results.report.html_fname);
</pre><h2 id="14">SOURCE ROI TIME-FREQUENCY PLOT</h2><p>As with the voxel example able, we can interrogate the OAT to extract the time-frequency plots from specific contrasts.</p><p>This time the results come from the parcel containing the requested voxel.</p><pre class="codeinput">mni_coord=[4,-82,-8]; <span class="comment">% Visual Cortex Voxel</span>

S2=[];
S2.vox_coord=mni_coord;
S2.stats=oat.first_level.results_fnames{1};
S2.oat=oat;
S2.first_level_cons_to_do = [3]; <span class="comment">% plots all of these contrasts</span>

[vox_ind_used] = oat_plot_vox_stats(S2);
</pre><img vspace="5" hspace="5" src="osl_example_beamformer_oat_03.png" alt=""> <h2 id="15">SOURCE ROI SINGLE-FREQUENCY POWER PLOT</h2><p>We may also isolate the results from a single frequency by defining the freq_inds parameter. The code below will plot the OAT results over time for the 8Hz frequency band.</p><p>Note that first two contrasts in the GLM are testing whether the power at a given time and frequency is different from zero. As such the COPE and t-stats return high values, even within the pre-stimulus period. This reflects the fact that there is always some power at 8Hz, though the later time-points clearly indicate that this power is modulated by stimulus onset.</p><p>The faces-motorbikes contrast is looking for differences in power. This quantity is not strictly positive so we do see t-values around zero in the prestimulus period.</p><p>Taken together, these results indicate that there is none-zero power at 8Hz through the epoch, though it is modulated by stimulus onset, moreover faces show a greater modulation of power than motorbikes.</p><pre class="codeinput"><span class="comment">% Load first level results</span>
stats=oat_load_results(oat,oat.first_level.results_fnames{1});

<span class="comment">% Define frequency of interest</span>
freqbin=nearest(stats.frequencies,8); <span class="comment">% find bin for 8Hz</span>

<span class="comment">% Define location of interest</span>
mni_coord=[4,-82,-8]; <span class="comment">% Visual Cortex Voxel</span>

S2=[];
S2.vox_coord=mni_coord;
S2.stats=stats;
S2.oat=oat;
S2.freq_inds=freqbin;
S2.first_level_cons_to_do=[2,1,3]; <span class="comment">% plots all of these contrasts</span>
[vox_ind_used] = oat_plot_vox_stats(S2);
</pre><img vspace="5" hspace="5" src="osl_example_beamformer_oat_04.png" alt=""> <p class="footer"><br><a href="http://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2014b</a><br></p></div><!--
##### SOURCE BEGIN #####
%% OAT 3 - Sourcespace Analysis
% This practical will work with a single subject's data from an emotional
% faces experiment (Elekta Neuromag data).
%
% Work your way through the script cell by cell using the supplied dataset.
% As well as following the instructions below, make sure that you read all
% of the comments and understand each step as you go.
%
% We will estimate neural activity in the brain's source space using a beamformer algorithm, 
% task dependant differences in this source activity is then quantified using a GLM. 
% This will go through the following steps:
%
% # Set-up an OAT Analysis: source_recon and first_level
% # Run source space GLM fitting and contrasts
% # Check coregistration
% # Save and view t-stat volumes
% # GLM analysis in an ROI
% # Time-frequency analysis in an ROI
% # Whole brain time-frequency analysis
%
% This practical requires the first part of the osl_example_coregistration
% practical to be run first. If you haven't run this before, please do so
% before starting this session.

%% INITIALISE GLOBAL SETTINGS FOR THIS ANALYSIS
% This cell sets the directory that OAT will work in. Change the workingdir variable to correspond to the correct directory on your computer before running the cell.

% directory where the data is:
datadir = fullfile(osldir,'example_data','faces_singlesubject','spm_files');
structdir =  fullfile(osldir,'example_data','faces_singlesubject','structurals');

% directory to put the analysis in
workingdir = fullfile(osldir,'example_data','faces_subject1_data_osl2');



%% SET UP THE SUBJECTS FOR THE ANALYSIS
%
% Specify a list of the fif files, structural files (not applicable for this practical) and SPM files (which will be created). It is important to make sure that the order of these lists is consistent across sessions. Note that here we only have 1 subject, but more generally there would be more than one. For example:
%
% |fif_files{1}=[testdir '/fifs/sub1_face_sss.fif'];|
%
% |fif_files{2}=[testdir '/fifs/sub2_face_sss.fif'];|
%
% etc...
%
% |spm_files{1} = [workingdir '/sub1_face_sss.mat'];|
%
% |spm_files{2} = [workingdir '/sub2_face_sss.mat'];|
%
% etc...

% clear old spm files
clear spm_files_continuous spm_files_epoched

spm_files_continuous{1}=[datadir '/Aface_meg1.mat'];
spm_files_epoched{1}=[datadir '/eAface_meg1.mat'];

%% SETUP THE OAT:
%
% The oat.source_recon options define the parameters for the data
% filtering, windowing and beamforming. We define the D files, conditions
% and time-frequency options in the same way as the sensorspace OAT. THe
% In this section we will do a wholebrain beamformer, followed by a trial-wise
% GLM that will correspond to a comparison of the ERFs for the different
% conditions. The source-space projection is defined by a new set of
% options.
%
% The critical options are:
%
% * |method| -   This defines the source reconstruction method to be used. other options include 'beamform_bilateral' and 'mne_datacov' 
% * |normalise_method| - How to normalise the magnetometers and gradiometers
% * |gridstep| - This is the distance (in mm) between points to be reconstructed, the spatial resolution of the analysis. We
% are using 8mm which is lower than usual but faster to compute.
% * |forward_meg| - This specifies the forward model used.
% * |modalities| - Defines which types of sensor to use.
% * |do_source_variance_maps| - If set to 1, this outputs an optional sanity check

% These options are the same as the sensorspace OAT and define input-data,
% conditions, filtering and windowing.
oat=[];
oat.source_recon.D_continuous=spm_files_continuous;
oat.source_recon.D_epoched=spm_files_epoched;

oat.source_recon.conditions={'Motorbike','Neutral face','Happy face','Fearful face'};
oat.source_recon.freq_range=[3 40]; % frequency range in Hz
oat.source_recon.time_range=[-0.2 0.4]; % time range in secs

% These options specify the source reconstruction that will take place.
oat.source_recon.method='beamform';
oat.source_recon.normalise_method='mean_eig';
oat.source_recon.gridstep=8; % in mm
oat.source_recon.forward_meg='Single Shell';
oat.source_recon.modalities{1}={'MEGPLANAR', 'MEGMAG'};
oat.source_recon.report.do_source_variance_maps=1;

oat.source_recon.dirname=[workingdir '/beamformer_erf']; % directory the oat and results will be stored in


%% SPECIFIY FIRST LEVEL OPTIONS
%
% These options are the same as the sensorspace ERF tutorial.
%
% design_matrix_summary is a parsimonious description of the design matrix.
% It contains values |design_matrix_summary{reg,cond}|, where reg is a regressor no. and cond
% is a condition no. This will be used (by expanding the conditions over
% trials) to create the (num_regressors x num_trials) design matrix:
design_matrix_summary={};
design_matrix_summary{1}=[1 0 0 0];design_matrix_summary{2}=[0 1 0 0];design_matrix_summary{3}=[0 0 1 0];design_matrix_summary{4}=[0 0 0 1];
oat.first_level.design_matrix_summary=design_matrix_summary;

% contrasts to be calculated:
oat.first_level.contrast={};
oat.first_level.contrast{1}=[3 0 0 0]'; % motorbikes
oat.first_level.contrast{2}=[0 1 1 1]'; % faces
oat.first_level.contrast{3}=[-3 1 1 1]'; % faces-motorbikes
oat.first_level.contrast_name={};
oat.first_level.contrast_name{1}='motorbikes';
oat.first_level.contrast_name{2}='faces';
oat.first_level.contrast_name{3}='faces-motorbikes';
oat.first_level.report.first_level_cons_to_do=[2 1 3];

oat.first_level.time_range=[-0.1 0.3];
oat.first_level.post_tf_downsample_factor=1;
oat.first_level.name=['wholebrain_first_level'];

oat = osl_check_oat(oat);

%% RUN THE OAT:
%
% We only need to run the source_recon and first_level stages in this
% tutorial, the subject_level and group_level options can be set to 0.
%
% The OAT will produce and close a number of figures as it processes, we
% will discuss what they mean once it has finished (this takes a couple of
% minutes)

oat.to_do=[1 1 0 0];
oat = osl_run_oat(oat);


%% VIEW OAT  REPORT
%
% Once finished, the OAT will print a link to a html report. Click to open
% it in the matlab html browser.
%
% *Source Recon*
%
% Firstly, click to open the "Session_1_report". This contains the plots
% relevent to the source_recon. In our case this is the sensor
% normalisation. Note that the eigenspectrum of the sensordata
% ('Pre-normalised log eigenspectrum') drops off sharply at
% around 64, this indicates the rank of the sensor data which i limited by
% maxfilter de-noising.
%
% The Pre-normalised variances shows the sensor-by-sensor variance across
% time. Channels 205-306 are the Magnetometers and have much higher
% variance than the Gradiometers. We need to normalise the data to remove
% this disparity or the information in the Magnetometers will dominate the
% reconstruction.
%
% In the normalised_eigs plot below, we can see that the 'mean_eig' sensor
% normalisation has both removed the shelf in the eigenspectrum and brought
% the sensor variances in line with each other.
%
% *First Level*
%
% Click back to the first page and on to the 'First level (epoched) report'
% and then the 'session1 report'. This contains a results summary from the
% voxel-wise GLM
%
% Design matrix plot. At the top is the design matrix used for each subject. 
% Red values indicate a value of 1, blue indicates a value of zero. It is worth 
% noting if every regressor (in this case corresponding to the four different conditions) 
% is well represented. For example, if aggressive amounts of outlier rejection has been 
% applied then it is possible to end up with very few trials in a regressor.
%
% *Stats plots* These show the time courses of the COPEs and t-stats for the 
% different contrasts listed in |oat.first_level.report.first_level_cons_to_do|, 
% at the MNI coordinated indicated in the title of the plots. This MNI coordinate 
% is chosen by finding the voxel with the maximum t-stat for the first contrast 
% listed in |oat.first_level.report.first_level_cons_to_do|. 
%
% The COPE is on the left and the t-stat on the right.
% Note the large peak around 96ms after stimulus onset.
%
% *COPE and t-stat orthoview plots* These show orthoviews of the COPEs and t-stats 
% for the different contrasts listed in |oat.first_level.report.first_level_cons_to_do|, 
% at the time point indicated in the title of the plots. This time point is chosen 
% by finding the time point with the maximum t-stat for the first contrast listed in 
% |oat.first_level.report.first_level_cons_to_do|.
%
% This time-point is around 136ms and shows peaks in lateral and
% medial occipital cortex. These are right hemisphere lateralised for the
% Faces and Faces-Motorbikes condition.
%
% <<osl_example_beamformer_oat_cope_at_maxt_smap_c2.png>>

%% OUTPUT SUBJECT'S NIFTII FILES
%
% The html report gives a brief summary of the results but we would like to
% go into more detail.
%
% We can do this by saving the contrast of parameter estimates (COPEs) and
% t-statistics for each of our contrasts to NIFTI images.

S2=[];
S2.oat=oat;
S2.stats_fname=oat.first_level.results_fnames{1};
S2.first_level_contrasts=[3,1,2];
S2.resamp_gridstep=oat.source_recon.gridstep;
[statsdir,times,count]=oat_save_nii_stats(S2);

%% OPEN NIFTII RESULTS IN FSLVIEW
% We can now view the nifti images containing our GLM results in FSL, here
% we are running fslview from the matlab command line, but you do not need
% to - you can run it from the UNIX command line instead.

mni_brain=[osldir '/std_masks/MNI152_T1_' num2str(S2.resamp_gridstep) 'mm_brain.nii.gz'];

% Inspect the results of an OAT contrast in FSLVIEW
contrast=2;
runcmd(['fslview ' mni_brain ' ' [statsdir '/tstat' num2str(contrast) '_' num2str(S2.resamp_gridstep) 'mm'] ' &']);

%% VIEW RESULTS IN FLSVIEW
%
% The previous command should have opened FSLVIEW with the t-stats for the
% faces contrast. We need to tweat the viewing settings to see the results
% well.
%
% Firstly, make sure the 'tstat2_8mm' image in selected by clicking on it
% once in the bottom window. Next set the 'Min' and 'Max' to 15 and 25
% respectively in the two boxes in the middel at the top of the screen.
%
% We are currently looking at the first time-point in the source_recon
% window which corresponds to -100ms, in which not much is happening.
%
% Change the 'Volume' in the bottom left to 49, this corresponds to around
% 100ms after stimulus onset. You should see a response in early visual
% cortex at the back of the brain. You can cross-check the times referred
% to in the Volumes with the 'times' variable returned by
% 'oat_save_nii_stats' above (Note that FSLVIEW indexes Volumes from 0 and
% Matlab indexes times from 1)
%
% Now change the 'Volume' to 59, corresponding to around 140ms after
% stimulus onset. The peak of activation jumps to the right hemiphere
% visual cortex.
%
% You can futher investigate the results by clicking on the
% 'Tools->Timeseries' option in the top menu. This will bring up and new
% window showing the t-value across time for the voxel under the green
% curser. You can navigate across space by clicking on a part of the brain
% and time by clicking at a time-point on the timeseries.
%
% Try changing to code in the previous cell to bring up the tstats for
% contrast 3 'Face-Motorbikes'. Following the same visualisation
% instructions you should be able to see that the early time-window (Volume
% 49) does not contain any large responses whereas the later response
% (Volume 59) still occurs. This indicates that there are no large
% differences between Faces and Motorbikes in the the early response,
% whereas the later response does differ.

% Display the vector of times associated with Volumes in the Nifti output.
disp(times)

%% INVESTIGATING LOCATION OF INTEREST USING AN MNI COORDINATE
%
% We may want to see the results across all contrasts for a single ROI to
% gain another perspective on our results.
%
% Here we will interrogate the wholebrain OAT (run above) using
% a specified MNI coordinate. 
%
% Run the code below now. This will bring up a the COPE and tstat
% estimates across time for a voxel in visual cortex. Note the prominant
% response around 100ms
%
% Try changing the code to run at 32,-64,-18
%
% This corresponds to a point in Right Hemisphere Fusiform Cortex. Note
% that the 100ms response does not appear here, rather the later Face
% specific response is more dominant.

mni_coord=[4,-82,-8]; % Visual Cortex Voxel

S2=[];
S2.vox_coord=mni_coord;
S2.stats=oat.first_level.results_fnames{1};
S2.oat=oat;
S2.first_level_cons_to_do=oat.first_level.report.first_level_cons_to_do; % plots all of these contrasts

[vox_ind_used] = oat_plot_vox_stats(S2);

%% INVESTIGATING REGIONS OF INTEREST USING AN MNI MASK
%
% In this section we will interrogate the wholebrain OAT (run above) using an 
% ROI mask. Here we will use an MNI mask of the right temporal occipital fusiform cortex, 
% to perform first level statistics restricted to the mask. The final result 
% will correspond to a spatial average over the mask.
%
% Unlike the virtual electrode, the results from many voxels (all defined in 
% the binary mask in |S2.mask_fname|) are extracted and the average results across these points presented.
%

% Apply a mask and spatially average the results over an ROI
S2=[];
S2.oat=oat;
S2.stats_fname=oat.first_level.results_fnames{1};
S2.mask_fname=fullfile(osldir,'example_data','faces_singlesubject','structurals','Right_Temporal_Occipital_Fusiform_Cortex_8mm.nii.gz');
[stats,times,mni_coords_used]=oat_output_roi_stats(S2);

% Plot the COPEs and t-stats within the ROI
S2=[];
S2.stats=stats;
S2.oat=oat;
S2.first_level_cons_to_do=oat.first_level.report.first_level_cons_to_do; % plots all of these contrasts
[vox_ind_used] = oat_plot_vox_stats(S2);



%% TIME-FREQUENCY ANALYSIS ACROSS A SOURCE-SPACE PARCELLATION
%
% Often we want to interrogate neuronal responses in the frequency domain
% rather than the time-domain ERF. As we saw in the sensor-space practical
% we can extend the OAT to compute the GLM across a time-frequency
% decomposition of the data. Here we will extend the
% analysis to compute the first level GLM across a detailed time-frequency
% decomposition. 
%
% The GLM across the full time-frequency decomposition takes much longer to compute than the
% ERF or power within a single frequency band. As such we will run a 
% time-frequency OAT across a 39 node source-space parcellation. 
%
% This has several benefits. Firstly, we can reduce noise by pooling across many voxels
% within a source parcel and secondly it is much faster to compute
% time-frequency transforms for 39 parcels than 306 Sensors or ~3500
% Voxels. The details of source parcellations are covered in the ROInets practical
% sessions - for the moment we can consider the parcellation to be simple way to
% compute the OAT across many Regions of Interest at the same time.
%
% Most of the OAT settings do not need to be changed for this analysis. 
% We just need to define which parcellation should be applied and add the time-frequency
% decomposition parameters in the first level.
%
% We are going to use the wholebrain OAT (which was run above), to make use of the settings and source_recon results already in there. 
% The new time-frequency parameters are:
%
% * |tf_freq_range| - The lower and upper bounds on the frequency range of interest 
% * |tf_num_freqs| - The number of frequency bands to estimate within the bounds in |tf_freq_range| 
% * |tf_method|-  The spectral power estimation method 
% * |tf_hilbert_freq_res| - The resolution to use in the hilbert spectral estimation 
% * |post_tf_downsample_factor|- How much to downsample the tf results
%
% The new parcellation parameters are defined within a
% |oat.first_level.parcellation| struct. the critical parameters are:
%
% * |parcellation| - The full path to a nifti file defining the
% parcellation
% * |orthogonalisation| - Option to reduce source leakage, in this case we
% will not apply correction
% * |method| - method for reconstructing parcel time-course. Options are
% |PCA|, |mean|, |peakVoxel| and |spatialBasis|.

% LOAD PREVIOUSLY RUN OAT
% We are going to use the wholebrain OAT (which was run above for the ERF
% analysis), to make use of the settings already in there
oat.source_recon.dirname=[workingdir '/beamformer_erf']; % Make sure this matches the dirname used above
oat.first_level.name=['wholebrain_first_level'];
oat=osl_load_oat(oat);

% Give the first level analysis a new name to avoid copying over previous
% first-level analyses:
oat.first_level.name=[oat.first_level.name '_parc' num2str(oat.first_level.parcellation.do)];

oat.source_recon.report.do_source_variance_maps=0;

% Add first level source recon options
oat.first_level.tf_freq_range=[4 30]; % frequency range in Hz
oat.first_level.time_range=[-0.1 0.3];
oat.first_level.tf_num_freqs=13;
oat.first_level.tf_method='morlet';
oat.first_level.post_tf_downsample_factor=1;

oat.first_level.report.time_range = [.08 .22];
oat.first_level.report.first_level_cons_to_do = [2,1,3];
oat.first_level.bc=[1 1 0]; % specifies whether or not baseline correction is done for the different contrasts

% Define the parameters for the parcellation
oat.first_level.parcellation.do=1;

% Path to the nifti defining the parcellation
parcellationfile=fullfile(osldir,'example_data','faces_singlesubject','structurals','fmri_d100_parcellation_with_PCC_reduced_2mm_ds8mm.nii.gz');

% Define the parcellation options.
oat.first_level.parcellation.parcellation=parcellationfile;
oat.first_level.parcellation.orthogonalisation = 'none';
oat.first_level.parcellation.method            = 'spatialBasis';

% Check and run the source_recon and first_level OAT stges
oat = osl_check_oat(oat);

% Rerun the first level OAT.
oat.to_do=[1 1 0 0];
oat = osl_run_oat(oat);

%% VIEW THE RESULTS IN THE OAT REPORT
%
% As with the other analyses, take a look at the first level summary
% report. Alongside the first level design matrix, this contains the COPE and t-stat estimates
% across the whole time-frequency decomposition from the peak ROI. The results 
% are uniform within each parcel in the whole brain orthoplots and indicate
% the largest responses around 116ms after stimulus onset are in visual
% cortex for all three contrasts.
% 

disp(oat.results.report.html_fname);

%% SOURCE ROI TIME-FREQUENCY PLOT
%
% As with the voxel example able, we can interrogate the OAT to extract the
% time-frequency plots from specific contrasts.
%
% This time the results come from the parcel containing the requested
% voxel.

mni_coord=[4,-82,-8]; % Visual Cortex Voxel

S2=[];
S2.vox_coord=mni_coord;
S2.stats=oat.first_level.results_fnames{1};
S2.oat=oat;
S2.first_level_cons_to_do = [3]; % plots all of these contrasts

[vox_ind_used] = oat_plot_vox_stats(S2);


%% SOURCE ROI SINGLE-FREQUENCY POWER PLOT
%
% We may also isolate the results from a single frequency by defining the
% freq_inds parameter. The code below will plot the OAT results over time
% for the 8Hz frequency band.
%
% Note that first two contrasts in the GLM are testing whether the power at
% a given time and frequency is different from zero. As such the COPE and
% t-stats return high values, even within the pre-stimulus period. This
% reflects the fact that there is always some power at 8Hz, though the
% later time-points clearly indicate that this power is modulated by
% stimulus onset.
%
% The faces-motorbikes contrast is looking for differences in power. This
% quantity is not strictly positive so we do see t-values around zero in
% the prestimulus period. 
%
% Taken together, these results indicate that there
% is none-zero power at 8Hz through the epoch, though it is modulated by stimulus onset,
% moreover faces show a greater modulation of power than motorbikes.

% Load first level results
stats=oat_load_results(oat,oat.first_level.results_fnames{1});

% Define frequency of interest
freqbin=nearest(stats.frequencies,8); % find bin for 8Hz

% Define location of interest
mni_coord=[4,-82,-8]; % Visual Cortex Voxel

S2=[];
S2.vox_coord=mni_coord;
S2.stats=stats;
S2.oat=oat;
S2.freq_inds=freqbin;
S2.first_level_cons_to_do=[2,1,3]; % plots all of these contrasts
[vox_ind_used] = oat_plot_vox_stats(S2);


##### SOURCE END #####
--></body></html>
